\newpage

\label[chap:strategies]

\chap Formal solution strategies

\pozn{Nezkontrolov√°no}In this chapter we present a survey on solution strategies, algorithms and techniques for the models described in chapter \ref[chap:models].

\sec Tabu search

A Tabu search, as presented in \cite[Glover1989,Glover1990a,Glover1990] 
is a solution strategy for solving combinatorial optimization problems. It can be used to solve 
a wide range of problems from graph theory and matroid settings to general pure and mixed integer programming problems. The combinatorial optimization problem is formulated as follows: 

$${\fam0 Minimize:}\quad c(x): x \in {\bf X}\quad {\fam0 in}\, {\bbchar R}_n,$$

where the function $c(x)$ is a function (linear or non-linear) and the condition $x\in X$ is assumed to constrain the specified components of $x$ to discrete values. The Tabu search itself 
can be defined as follows:

\begitems \style N
* Select an initial $x\in {\bf X}$ and let $x^\hv := x$. Set the iteration counter $k = 0$ and begin with ${\bf T}$ empty.
* If $S(x)\setminus {\bf T}$ is empty, go to Step 4. Otherwise, set $k := k+1$ and select $s_k \in S(x) \setminus T$ such that $s_k(x) = {\rm OPTIMUM}(s(x) : s \in S(x) \setminus T)$.
* Let $x := s_k(x)$. If $c(x) < c(x^\hv)$, where $x^\hv$ denotes the best solution currently found, let $x^\hv := x$.
* If a chosen number of iterations has elapsed either in total or since $x^\hv$ was last improved, or if $S(x) \setminus {\bf T} = \emptyset$ upon reaching this step directly from Step 2, stop.
Otherwise update ${\bf T}$ (as subsequently identified) and return to Step~2.
\enditems

\sec Parallel savings based heuristics

In \cite[Altinkemer1991], there is presented an approach based on weighted matching problem. The paper defines three versions of the algorithm -- a PSA1\glos{PSA1--3}{Parallel savings based heuristics algorithms}, which is not polynomial, a PSA2, which is fully
polynomial with a time complexity of $O(n^3)$. Finally, a PSA3 algorithm is an improvement of PSA2, which is not polynomial as well.

First we will introduce the notation used in the description of the algorithm:


\begitems
* $n$ is the number of nodes in the problem,
* ${\bf V}$ is the node set of the graph, $V = \{1, \dots, n\}$,
* $Q$ is the vehicle capacity,
* $d_i$ is the load to be delivered to node $i$ ($d_1 = 0$),
* ${\bf R}_p$ is the set of nodes in cluster $p$; this is the set of nodes assigned to vehicle $p$,
* $C({\bf R}_p)$ is the cost of the optimum travelling salesman tour over ${\bf R}_p$ and node ${\bf 1}$ (the depot),
* $S_{pq}$ is the savings obtained by merging clusters $p$ and $q$,
* ${\bf M}_i$ is a set of dummy nodes added to the network at iteration $i$; $|{\bf M}_i| = n - (i+1)T$ and $2 \leq T \leq 12$,
* $p_f$ is the first endpoint of the tour in cluster $p$,
* $p_l$ is the last endpoint of the tour in cluster $p$,
\enditems

The PSA1 algorithm is defined as follows:

\begitems \style N
* {\em (Initialization)} For $p = 1, \dots, n$, set ${\bf R}_p = \{p\}$, $i = 1$, ${\bf V}_0 = {\bf V}$, and choose a value for $T$.
* Form the dummy node set ${\bf M}_i$, such that $|{\bf M}_i| = n - (i+1)T$. For every $p$ and $q$, $p<q$ do

$$S_{pq} = \cases{0 & $p<q$ and $p,q \in {\bf M}_i$\cr -\infty & $p<q$ and $p\in {\bf V}_{i-1}$ and $q\in {\bf M}_i$}$$

\noindent For every $p$ and $q$, $p<q$ and $p, q \in {\bf V}_{i-1}$ do:

\begitems \style a
* If $\sum_{j\in {\bf R}_p \cup {\bf R}_q}{d_j} > Q$ go to the next combination of $p$ and $q$.
* Otherwise, compute $S_{pq}$ according to the formula

$S_{pq} = \cases{0 & if $p=1$, $q=1, \dots, |{\bf V}_{i-1}|$\cr C({\bf R}_p) + C({\bf R}_q) - C({\bf R}_p \cup {\bf R}_q) & otherwise}$
\enditems

* Solve the maximum weighted matching problem with ${\bf V}_{i-1}\cup {\bf M}_i$ as its node set, and $S_{pq}$ as the cost entry for arc $(p,q)$. Merge clusters $p$ and $q$ if arc $(p,q)$ is in the matching cluster
and $p,q \in {\bf V}_{i-1}$ unless either $p$ or $q$ is node ${\bf 1}$.
* If all mergers are non-admissible STOP, otherwise increase $i$ by one, update ${\bf V}_i$ to include all clusters and go to {\em Step 2}.
\enditems

Since the computation of $S_{pq}$ in {\em Step 2} involves solving of the optimum travelling salesman tour, it is not a polynomial algorithm. Therefore, a different formula is used for PSA2 and PSA3:

$$S_{pq} = \max\cases{
	c_{1p_f} + c_{1q_f} - c_{p_f q_f} \cr 
	c_{1p_f} + c_{1q_l} - c_{p_l q_l} \cr
	c_{1p_l} + c_{1q_l} - c_{p_l q_l} \cr
	c_{1p_l} + c_{1q_f} - c_{p_l q_f}
}$$

In PSA3, after the final clusters are formed using PSA2, a TSP is solved for each final cluster formed. The tour generated by the optimal travelling salesman tour of that cluster is selected as 
the solution for that cluster.

\sec Monte Carlo Tree Search

Monte Carlo Tree Search is a stochastic optimization algorithm combining classical tree search with random sampling of the search space. In \cite[Trunda2013] the MCTS\glos{MCTS}{Monte Carlo Tree Search} is used to solve
planning problems in transportation domains.

The MCTS algorithm builds an asymmetric tree to represent the search space by repeatedly performing four steps, which are illustrated on the figure \ref[fig:strategies:mcts]

\begitems \style N
* {\em Selection} -- the tree is traversed from the root to a leaf using some criterion called {\em tree policy} to select the most urgent leaf.
* {\em Expansion} -- all applicable actions for the selected leaf node are applied and the resulting states are added to the tree as successors of the selected node.
* {\em Simulation} -- a pseudo-random simulation is run from the selected node until some final state is reached. During the simulation the simulation the actions are selected by a {\em
simulation policy}.
* {\em Update/Back-propagation} -- the result of the simulation is propagated back in the tree from the selected node to the root and statistics of the nodes on this path are updated 
according to the result.
\enditems

\begfigure
\centerline{\inspic figs/strategies-mcts-1.pdf }\nobreak\medskip
\label[fig:strategies:mcts]\caption/f Basic schema of MCTS from \cite[Chaslot2006]
\endfigure

The MCTS was originally formulated in \cite[Chaslot2006] for the purposes of a game AI. However, as presented in \cite[Trunda2013], it is suitable for solving of planning problems.
In such a case the planning task is transformed to the problem of finding a shortest path in an implicitly given state space, where transitions/moves between the states are
defined by the actions. Though, classical path-finding techniques cannot be applied there because the state space is enormous.

The paper identifies a problem with the infiniteness of paths in the state space. Since most of the actions are reversible, there are cycles and even finite state space does not assure
that paths will be finite. There are specified three possible threats -- cycles in the state space, dead ends and dead components -- with possible ways to solve them.


\sec Branch and bound approach to solve VRP

``Branch and bound'' is a general algorithm for finding optimal solutions of optimization problems first described in \cite[Land1960] in 1960. The algorithm uses two tools, a splitting procedure and a bounds
procedure. The algorithm systematically enumerates possible solutions and use the upper and lower bounds to discard solutions which are not feasible. Therefore, there is no need to explore whole state
space to find a feasible solution.

In a survey paper \cite[Toth2002], there are presented several bounds procedures for cVRP problems. The paper presents a difference between symmetric cVRP (scVRP\glos{scVRP}{Symmetric cVRP}) and asymmetric cVRP (acVRP\glos{acVRP}{Asymmetric cVRP}) and propose different
bounds procedures for each of them. The cVRP is asymmetric if it has an asymmetric cost matrix. Otherwise, the cVRP is symmetric. The benchmarks showed, that the best bounds procedure for an acVRP is 
based on the additive approach which considers, in sequence, different infeasible arc subsets so as to produce a possibly better overall lower bound. Likewise, for the scVRP the benchmarks shows
that the best bounds procedure is based on $b$-matching, which is a counterpart for the symmetric version of the assignment relaxation for acVRP -- a bounds procedure based on transforming of the cVRP
to the assignment problem.


\sec Branch and cut algorithm

A slightly different approach than branch and bound is the ``branch and cut algorithm'', described in detail in \cite[Padberg1991]. First, the problem is formulated as a linear programming 
problem. Then, a solution is found. If the solution is not integer, the algorithm either splits one variable or adds a cutting plane. 

We will demonstrate this technique on an example from \cite[Mitchell2002]:

Let have an integer programming problem

\label[strategies:branch-and-cut:eq0]
$$\matrix{\min{z} := & -6x_1 & - & 5x_2 \cr
\mathbox{subject to } & 3x_1 & + &  x_2 & \leq & 11\cr
 & -x_1 & + & 2x_2 & \leq & 5\cr
 & & &  x_1,x_2 & \geq & 0,\mathbox{ integer}} \eqmark$$

First the algorithm solves the linear programming relaxation, giving the point $(2{3 \over 7}, 3{5 \over 7})$, with value $-33{1 \over 7}$. The algorithm has now a choice -- it can divide the problem to
two problems by splitting on a variable or add a cutting plane, for example $x_1 + x_2 \leq 5$.

\begfigure
\centerline{\inspic figs/strategies-branch-and-cut-1.pdf }\nobreak\medskip
\label[fig:strategies:branch-and-cut]\caption/f Branch-and-cut example from \cite[Mitchell2002]. The dots represents possible integer solutions, the dashed line is the convex hull of the integer points. The grayed area is a polyhedron used for linear programming if we ignore the integrality restrictions.
\endfigure

If the algorithm splits on $x_1$, two new problems are obtained:

\label[strategies:branch-and-cut:eq1]
$$\matrix{\min{z} := & -6x_1 & - & 5x_2 \cr
\mathbox{subject to } & 3x_1 & + &  x_2 & \leq & 11\hfill\cr
 & -x_1 & + & 2x_2 & \leq & 5\hfill\cr
 & {\bf x_1} & & & \geq & {\bf 3}\hfill\cr 
 & & &  x_1,x_2 & \geq & 0,\mathbox{ integer}} \eqmark$$

\noindent and

\label[strategies:branch-and-cut:eq2]
$$\matrix{\min{z} := & -6x_1 & - & 5x_2 \cr
\mathbox{subject to } & 3x_1 & + &  x_2 & \leq & 11\hfill\cr
 & -x_1 & + & 2x_2 & \leq & 5\hfill\cr
 & {\bf x_1} & & & \leq & {\bf 2}\hfill\cr 
 & & &  x_1,x_2 & \geq & 0,\mathbox{ integer}} \eqmark$$

The optimal solution to the original problem will be the better of the solutions to these two subproblems. The solution to the linear programming relaxation of \ref[strategies:branch-and-cut:eq1] is 
$(3,2)$, with value $-28$. This solution is integral, so it solves \ref[strategies:branch-and-cut:eq1], and becomes the incumbent best known feasible solution. The LP relaxation of 
\ref[strategies:branch-and-cut:eq2] has optimal solution $(2,3.5)$, with value $-29.5$. This point is non-integral, so it does not solve \ref[strategies:branch-and-cut:eq2], and it must be attacked 
further.

Assume the algorithm uses a cutting plane approach and adds the inequality  $2x_1+x_2\leq 7$ to \ref[strategies:branch-and-cut:eq2]. This is a valid inequality, in that it is satisfied by every 
integral point that is feasible in \ref[strategies:branch-and-cut:eq2]. Further, this inequality is violated by $(2,3.5)$, so it is a cutting plane. The resulting subproblem is 

\label[strategies:branch-and-cut:eq3]
$$\matrix{\min{z} := & -6x_1 & - & 5x_2 \cr
\mathbox{subject to } & 3x_1 & + &  x_2 & \leq & 11\hfill \cr
 & -x_1 & + & 2x_2 & \leq & 5\hfill \cr
 & x_1 & & & \leq & 2\hfill \cr 
 & {\bf 2x_1} & {\bf +} & {\bf x_2} & \leq & {\bf 7}\hfill \cr 
 & & &  x_1,x_2 & \geq & 0,\mathbox{ integer}} \eqmark$$

The LP relaxation of \ref[strategies:branch-and-cut:eq3] has optimal solution $(1.8,3.4)$, with value $-27.8$. Notice that the optimal value for this modified relaxation is larger than the value 
of the incumbent solution. The value of the optimal integral solution to the second subproblem must be at least as large as the value of the relaxation. Therefore, the incumbent solution $(3,2)$ is 
better than any feasible integral solution for \ref[strategies:branch-and-cut:eq3], so it actually solves the original problem.

\begfigure
\centerline{\inspic figs/strategies-branch-and-cut-2.pdf }\nobreak\medskip
\label[fig:strategies:branch-and-cut:2]\caption/f Progress of branch-and-cut on the two dimensional integer programming problem from \cite[Mitchell2002].
\endfigure

\begfigure
\centerline{\inspic figs/strategies-branch-and-cut-3.pdf }\nobreak\medskip
\label[fig:strategies:branch-and-cut:3]\caption/f Three steps of the algorithm branch-and-cut.
\endfigure

The branch-and-cut approach was applied to the VRP in \cite[Bard1998]. In the concrete, they used this approach to solve yhe Vehicle routing problem with satellite facilities (VRPSF).  
Their approach constists of the following steps:

\begitems \style N
* {\em (Preprocessing)} Set up directed graph and sparsify.
* {\em (Upper bound)} Obtain an upper bound on the MILP objective function by running a heuristic to find a feasible solution.
* {\em (Lower bound)} Solve the LP relaxation of the VRPSF.
* {\em (Optimality check)} If the optimality conditions are satisfied go to Step 8; otherwise go to Step 4.
* {\em (Variable fixing)} Determine if any binary variables can be fixed at zero or one.
* {\em (Cut generation)} Solve the separation problem to generate valid inequalities. If no such inequalities can be identified go to Step 7; otherwise go to Step 2.
* {\em (Branching)} Create a new node in the search tree following the logic of branch and bound. If branching is not possible, go to Step 8; otherwise go to Step 2.
* {\em (Desparsification)} If no sparsified variables remain fixed at zero, stop and declare the incumbent the optimal solution to the MILP. Otherwise, introduce a subset of the sparsfied variables whose
reduced costs are negative back into model and go to Step 2.
\enditems

\sec A local search/constraint propagation hybrid

A technique described in this section is suitable for routing of demands through a computer network.

In \cite[Lever2005], there is presented a hybridisation of local search and constraint programming techniques. This hybrid algorithm is suitable for routing of new demands through a network, with several
already routed previous demands. The hybrid algorithm consists of the following steps: 

\begitems \style N
* Obtain an initial solution, using Constrained shortest path first (CSPF)\glos{CSPF}{Constrained shortest path first} methods. 
* Improve the initial solution incrementally by adding in demands not yet placed and using local search to restore consistency with respect to the link capacity constraints.
* Execute a hybrid brach-and-bound tree search in which alternative combinations of placed and unplaced demands are considered, with local search again used to restore consistency.
\enditems

The CSPF algorithm, described in \cite[Lee1995], compute the shortest path fulfilling a set of constraints. In this particular case the demands are ordered in order of cost, highest first. The demand
must satisfy the bandwidth requirement of the demand without violating available link capacities. The metric used is the reciprocal of the free capacity remaining on the link if the demand were routed
over it.If a valid path is found for a demand, it is placed on the network -- the required bandwidth is subtracted from the free capacity.

Then in the incremental improvement phase we seek to extend the set of demands placed in the initial solution in a loop which proceeds as follows:

\begitems \style N
* Choose an unplaced demand.
* Place it on the network, allowing violations of the link capacity constraints.
* Call a local search procedure that attempts to restore consistency by rerouting demands.
\enditems

Next, the hybrid tree search phase of the algorithm constructs a branch-and-bound search tree with the aim of optimising the total cost of the unplaced demands. Each demand $D_i$ is associated with 
a boolean variable $B_i$, which has the value 1 if, and only if, the associated demand is routed. The total cost is thus given by $\sum_i{(1-B_i){\rm cost}(D_i)}$.

Finally, the local search procedure restores the consistency in an inconsistent demand placement. This procedure is a key component of both the incremental improvement ad hybrid three search phases 
of the algorithm. Essentially, local search algorithms maintain a current search space, and proceed by moving from one state to another by computing a ``neighbourhood" of a state, and selecting 
a neighbouring state to move on. In this algorithm, a state is defined by the routes of all routed demands and the neighbourhood of a state is defined as all states that can result from rerouting
a demand whose route includes the link whose capacity is exceeded maximally so that the demand's route no longer includes that link.

\sec A hybrid multicommodity routing algorithm

The algorithm proposed in \cite[Ouaja2004] is a hybrid algorithm combining the Lagrangian optimization and Constraint programming search solving the traffic placement (TP) problem\glos{TP}{Traffic 
placement problem}. The TP is stated as follows:

\begitems \style N
* Given a network composed of nodes and links, each link with a maximum capacity, a set of traffic demands defined by their source/destination nodes and required bandwidth values, respectively;
* Find a route for each demand such that no link capacity is exceeded, while optimizing a predefined objective function.
\enditems

\secc Lagrangian relaxation

The TP can be formulated as an integer linear multicommodity flow program as follows:

$$z^* = \min{{1\over |E|}\sum_{k \in {\bf K}}\sum_{(i,j)\in {\bf E}}{{d_k\over b_{ij}} X_{ij}^{k}}} \eqmark$$

\label[eq:strategies:lr:2]
$$\sum_{j:(i,j) \in {\bf E}}{X_{ij}^{k}} - \sum_{j:(j,i)\in {\bf E}}{X_{ji}^k} = \cases{\hfill 1 & $i=s_k$\cr -1 & $i=t_k$\cr\hfill 0 & $i \neq s_k, t_k$}\quad\forall i\in {\bf V}, k\in {\bf K} \eqmark$$

\label[eq:strategies:lr:3]
$$\sum_{k \in {\bf K}}{d_k X_{ij}^k} \leq b_{ij}\quad\forall (i,j) \in {\bf E} \eqmark$$

$$X_{ij}^k \in \{0,1\}\quad \forall(i,j) \in {\bf E}, k\in {\bf K} \eqmark$$

Where the network $G=({\bf V},{\bf E})$ is a digraph with a set of nodes ${\bf V}$ and a set of directed links ${\bf E}$. Each link $(i,j)$ hs a capacity $b_{ij}$. $K$ is the given set of demands $k \in {\bf K}$, defined as 
a tuple $(s_k,t_k,d_k)$. The $s_k$ denotes the source node, the $t_k$ denotes the destination node and $d_k$ denotes required bandwidth of a demand $k$. For each edge $(i,j)$ and demand $k\in {\bf K}$, we
define a variable $X_{ij}^k$ to represent proportion of $k$'s bandwidth that crosses $(i,j)$. 

Let $x$ be the vector of all variables $X_{ij}^k$ and $c$ be the vector of corresponding objective coefficients. Let $Nx=n$ and $Dx\leq b$ be, respectively, the matrix-based formulation of the flow
constraints \ref[eq:strategies:lr:2] and resource constraints \ref[eq:strategies:lr:3].

We can rewrite the TP as follows:

\label[eq:strategies:lr:P]
$$\matrix{
z^* & = & \min cx \hfill\cr
\mathbox{such that} && Dx\leq b \hfill\cr
&& x\in X:\{x\in \{0,1\}|Nx = n\}.
} \eqmark$$

We apply the lagrangian relaxation on \ref[eq:strategies:lr:P] by dualizing the hard constraints $Dx\leq b$ into the objective function with an associated vector of non-negative {\em Lagrangian
multipliers $\lambda$}. The resulting problem

$$\matrix{
L(\lambda) & = & \min cx + \lambda(Dx - b)\hfill\cr
&&\mathbox{s.t. } x\in X\hfill
}, \eqmark$$ % just for tex... $$

\noindent is called the {\em Lagrangian subproblem $P_\lambda$}.

\secc The hybrid algorithm

The algorithm explores a binary search tree as shown on the Figure \ref[fig:strategies:hlr]. Each node of the tree has attached a Lagrangian subproblem $P_\lambda$ and a constraint store $CS$ sharing
the problem variables, which are incrementally maintained. LR optimization operates on the subproblem $P_\lambda$ by performing a number of sub-gradient optimization operations. 

\begfigure
\setbox1=\hbox{\inspic figs/strategies-hlr-1.pdf }
\setbox0=\vbox{\advance\hsize by -4mm \advance\hsize by-\wd1
\iindent=2mm\male\baselineskip=11pt
\begitems \style N
* While $LR$ optimization of $P_\lambda$ do
\begitems \style a
* $LR$ adds new constraints to the constraint store CS
* $CS$ performs propagation and feeds back new fixed variables to $LR$.
\enditems
* Based on $LR$ solition create a choice point $(D \wedge \neg D)$.
\enditems
}
\hbox to\hsize{\vbox to\ht1{\vfil\box0\vfil}\hfill\box1}\nobreak\medskip
\label[fig:strategies:hlr]\caption/f Illustration of HLR constraint-based search from \cite[Ouaja2004].
\endfigure

Sub-gradient
optimization operations, as described in \cite[Held1974], iteratively updates $\lambda$ along a tentative search direction (sub-gradient) which increases $L(\lambda)$. The vector $D_{x_\lambda} - b$,
with $x_\lambda$ being the optimal solution of $P_\lambda$, is always a sub-gradient of $L$ at $\lambda$. Therefore, starting from an initial multiplier vector $\lambda^0$, say $\lambda^0=0$, SG
interleaves two steps:

\begitems \style N
* Solve $P_{\lambda^i}$. Let $L_i$ and $x_i$ be the optimal objective value and optimal solution, respectively. If the stopping conditions are satisfied, terminate the procedure; otherwise, go to Step 2.
* Update the vector of multipliers such that $\lambda^{i+1} = \max(0, \lambda^i + \theta_i(Dx_i - b))$, where $\theta_i$ is a positive step-size parameter. Increment $i$, go to Step 1.
\enditems 

SG stops when it converges, a specified limit of iterations is reached, or the step-size becomes sufficiently small.

After each SG iteration, new constraints taking account of capacity violations and reduced costs are dynamically generated and added to CS. Propagation is then performed on CS to 1) infer new fixed 
variables or 2) detect a failure. In case 1), the next iteration SG tackles a reduced easier problem, whereas in case 2), the node is pruned immediately; no need to execute further local SG iterations.

When LR optimization stops, a Lagrangian solution corresponding to a total assignment to all variables is returned. Note that this might be partially inconsistent, violating some capacity constraints.
At this point, HLR\glos{HLR}{Hybrid Lagrangian relaxation} heuristically selects a branching constraint $D$ and adds it to $P_\lambda$ and $CS$. On backtracking, $D$ is revoked and its negation $\neg D$ is added instead. 


