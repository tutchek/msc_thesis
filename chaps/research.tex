\newpage

\label[chap:models]

\chap Related research

\pozn{Zkontrolovano: 27.7.2014}In this chapter, we review useful models and techniques which help us formulate a model for the problem described in chapter \ref[chap:analysis].

\sec Transportation problems

In \cite[Helmert2003], there is described a Transport task as a 9-tuple
$({\bf V},\penalty0 {\bf M},\penalty0 {\bf P},\penalty0 l_0,\penalty0$ ${\bf P}_G,\penalty0 l_G,\penalty0 fuel_0,\penalty0 cap,\penalty0 road)$, where

\begitems
* ${\bf V}$ is a finite set of {\em locations},
* ${\bf M}$ is a finite set of {\em mobiles},
* ${\bf P}$ is a finite set of {\em portables},
* $l_0:({\bf M} \cup {\bf P}) \to {\bf V}$ is the {\em initial location} function,
* ${\bf P}_G \subseteq {\bf P}$ is the set of {\em goal portables},
* $l_G: {\bf P}_G \to {\bf V}$ is the {\em goal location} function,
* $fuel_0:{\bf V} \to {\bbchar N} \cup \{\infty \}$ is the {\em initial fuel} function,
* $cap: {\bf M}\to {\bbchar N}$ is the {\em capacity} function, and finally
* $road: {\bf M}\to {\cal P}(V \times V)$ is the {\em roadmap} function.
\enditems

We require that $V, M, {\fam 0 and\ } P$ are disjoint, and that $(V, road(m))$ is an undirected graph for all $m \in M$ (i.e., for all $m \in M$, the relation $road(m)$ is symmetric and irreflexive).

\secc Vehicle routing problem

In logistics, there are widely used algorithms which can be classified as transportation problems. A large group of them is a variation to the Vehicle routing problem (VRP\glos{VRP}{Vehicle routing 
problem}). The problem was first defined as a Capacitated vehicle routing problem (cVRP \glos{cVRP}{Capacitated vehicle routing problem}) in \cite[Dantzig1959]. The problem deals with a situation 
where there is a need to plan routes of vehicles with a limited capacity from a central depot to destination depots. This problem is well researched and there exists many modifications to it.

In \cite[Braysy2005], there is defined a Vehicle routing problem with time windows (VRPTW\glos{VRPTW}{Vehicle routing problem with time windows}). The key difference to cVRP is that the depots
can be serviced within a specified time interval or time window. This variation of VRP is widely used and well researched and there are available many heuristics to solve it. 

Another variation of VRP is a Stochastic vehicle routing problem (SVRP\glos{SVRP}{Stochastic vehicle routing problem}). As presented in \cite[Gendreau1996], stochastic vehicle routing problems 
arise whenever some elements of the problem are random, for example stochastic demands or stochastic travel times. The paper describes an approach using stochastic programming. Such a stochastic 
program is modelled in two stages -- the first is ``a priori'' solution and the second is a ``corrective action''.
A stochastic program is usually modelled either as a {\em chance constrained program} (CCP\glos{CCP}{Chance constrained program}), where the solution is searched with respect to a particular threshold for a probability of a failure, or
as a {\em stochastic program with recourse} (SPR\glos{SPR}{Stochastic program with recourse}) minimising the expected cost of the second stage solution plus the expected net cost of a recourse.
The SVRPs are usually modelled as mixed or pure integer stochastic programs or as Markov decision processes.

The most studied problem in this class is the {\em Vehicle Routing Problem with Stochastic Demands} (VRPSD\glos{VRPSD}{Vehicle Routing Problem with Stochastic Demands}). In this problem, customer demands are independent random variables.
The next is the {\em Vehicle Routing Problem with Stochastic Customers} (VRPSC\glos{VRPSC}{Vehicle Routing Problem with Stochastic Customers}) with customers who are present with some probability but have deterministic demands. A combination of both
previously mentioned problems is the Vehicle Routing Problem with Stochastic Customers and Demands (VRPSCD\glos{VRPSCD}{Vehicle Routing Problem with Stochastic Customers and Demands}). This problem is extremely hard to solve.

\secc Scheduling

In \cite[Beck2002] the VRP is reformulated as a scheduling problem. However, these reformulations do not have the same performance. As described in the paper, in an optimisation task,
the VRP is better in minimising the total travelled distance whereas the scheduling technology is better in finding the quickest solution. In the existence task was the VRP itself
significantly worse than the scheduling technology. Though, the VRP technology can be used to improve results of the scheduling technology.

Different approach represents the DARSP\glos{DARSP}{Daily aircraft routing and scheduling problem} described in \cite[Desaulniers1997]. The problem is to generate a schedule for a heterogeneous aircraft fleet covering a set of operational flight legs 
with known departure time windows, durations and profits according to the aircraft type. In the cited paper the problem is defined as follows: {\it ``Given a heterogeneous aircraft fleet, a set
of operational flight legs over a one-day horizon, departure time windows, durations and costs / revenues according to the aircraft type for each flight leg, find a fleet schedule that maximises 
profits and satisfies certain additional constraints.''}

In the paper, there are two formulations of the DARSP. The first is based as a Set Partitioning with additional constraints and the second as the time constrained multi-commodity network flow
formulation. For each of the formulations, the paper proposes a solution strategy. For the Set Partitioning approach, the branch-and-bound strategy is feasible and for the multi-commodity network flow
the Dantzing-Wolfe or Lagrangean relaxation embedded in a branch-and-bound search tree.

\secc Solution strategies

There exists several solution strategies to solve transportation problems. The first group of them are based on local search of state space. The strategy searches through the space of candidate solutions
and moves from one solution to another until it finds an optimal solution. As an example, we mention Tabu search, described in \cite[Glover1989,Glover1990a,Glover1990]. This method maintains a list
of a forbidden candidate solution (e.g. previously visited solutions or solutions violating a certain rule) to enhance the search performance.

In \cite[Altinkemer1991], the VRP is transformed to weighted matching problem, which is afterwards solved using the Parallel savings based heuristics algorithm (PSA\glos{PSA}{Parallel savings 
based heuristics algorithm}). They present three variants of PSA, but only one of them is a polynomial algorithm with a time complexity $O(n^3)$.

Another approach is presented in \cite[Trunda2013], where the transportation tasks are solved using a stochastic technique. The paper presents a Monte Carlo Tree Search (MCTS\glos{MCTS}{Monte Carlo Tree Search}), a stochastic optimization algorithm combining classical tree search with random sampling of the search space. The MCTS algorithm builds an asymmetric tree to represent the search space by repeatedly performing four steps, which are illustrated on figure \ref[fig:strategies:mcts]

\begitems \style N
* {\em Selection} -- the tree is traversed from the root to a leaf using some criterion called {\em tree policy} to select the most urgent leaf.
* {\em Expansion} -- all applicable actions for the selected leaf node are applied and the resulting states are added to the tree as successors of the selected node.
* {\em Simulation} -- a pseudo-random simulation is run from the selected node until some final state is reached. During the simulation, the actions are selected by a {\em
simulation policy}.
* {\em Update/Back-propagation} -- the result of the simulation is propagated back in the tree from the selected node to the root. Statistics of the nodes on this path are updated
according to the result.
\enditems

\begfigure
\centerline{\inspic figs/strategies-mcts-1.pdf }\nobreak\medskip
\label[fig:strategies:mcts]\caption/f Basic schema of MCTS from \cite[Chaslot2006]
\endfigure 

For a non-stochastic tree search, we can use a ``branch and bound'' algorithm. It is a general algorithm for finding optimal solutions of optimization problems first described in 
\cite[Land1960] in 1960. The algorithm uses two tools, a splitting procedure and a bounds procedure. The algorithm systematically enumerates possible solutions and uses the upper and lower 
bounds to discard solutions which are not feasible. Therefore, there is no need to explore the whole state space to find a feasible solution. As presented in \cite[Toth2002], there exists
several bounds procedures.

In a survey paper \cite[Toth2002], there are presented several bounds procedures for cVRP problems. The paper presents a difference between symmetric cVRP (scVRP\glos{scVRP}{Symmetric cVRP}) and asymmetric cVRP (acVRP\glos{acVRP}{Asymmetric cVRP}) and proposes different
bounds procedures for each of them. The cVRP is asymmetric if it has an asymmetric cost matrix. Otherwise, the cVRP is symmetric. The benchmarks showed that the best bounds procedure for an acVRP is 
based on the additive approach which considers, in sequence, different infeasible arc subsets so as to produce possibly a better overall lower bound. Likewise, for the scVRP the benchmarks shows
that the best bounds procedure is based on $b$-matching, which is a counterpart to the symmetric version of the assignment relaxation for acVRP -- a bounds procedure based on a transformation of the cVRP
to the assignment problem. 

By adding a cutting planes, we get a ``branch and cut algorithm'', described in detail in \cite[Padberg1991]. The branch-and-cut approach was applied to the VRP in \cite[Bard1998]. Specifically, they used this approach to solve the Vehicle routing problem with satellite facilities (VRPSF\glos{VRPSF}{Vehicle routing problem with satellite facilities}).  


\secc Transportation problem and ALP

The transportation problems do not fit well with ALP. The key feature of a transportation problem is a fleet of vehicles with a limited capacity. However, in ALP there is no such condition. 
In ALP-lp, stores have a limited capacity. However, the stores correspond to locations in vehicle routing problems. On the other hand, in ALP and ALP-lp, there is no capacity constraint 
to the delivery routes. They are provided by outsourced delivery companies and are in a practical case unlimited.

\label[sec:research:network-flows]
\sec Network flows

Graph algorithms represent a different approach. The task of ALP is to optimally distribute goods from one store to another. This resembles network flows problem, which aims to find a maximum flow
in a given network. Finding the maximum flow is not difficult. However, if we generalize the problem and try to search a maximum flow for more than one flow, the problem becomes NP-hard.
As described in \cite[Leong1993], a multicommodity flows problem involves a simultaneous shipping of multiple commodities through a single network so that the total amount of flows on each edge is no bigger than the capacity of the edge.


We can formally describe the Multicommodity flows as follows: Given an undirected graph $G = (V,E)$ with a positive capacity $c(uv)$ for each edge $uv \in E$ and a set of commodities numbered $1$ through $k$, where each commodity $i$ is specified by a source-sink pair $s_i,t_i \in V$ and a positive demand $d_i$. For each commodity $i$, an amount proportional to its demand $d_i$ is shipped from its source
$s_i$ to its sink $t_i$. This gives a {\em single commodity flow} $f_i$ specified by a set of edge flows $f_i(vw)$ on edges $vw \in E$ where each edge has an arbitrary direction to keep track 
of which way the flows travel across it. A positive edge flow $f_i(vw) > 0$ denotes a forward flow of commodity $i$ with respect to the direction of edge $vW$, while a negative flow $f_i(vw) < 0$ denotes a backwards flow. A {\em multicommodity flow} $f$ consists of $k$ single commodity flows, one for each commodity. In a multicommodity flow $f$, the total flow $f(vw)$ on each edge $vw \in E$ equals the
sum $\sum_{i=1}^k{|f_i(vw)|}$ of the single commodity flows on that edge.

\begfigure
\centerline{\inspic figs/multiflows-1.pdf }\nobreak\medskip
\label[fig:models:multiflows]\caption/f An example of multicommodity flows graph -- edges have capacities $c_1$ through $c_9$ and nodes $s_1$, $s_2$, $t_1$ and $t_2$ represent sources, or more precisely sinks
for two commodities. The dotted line represents a flow for commodity 1 and a dashed line represents a flow for commodity 2.
\endfigure

However, as in case of transportation problem, this approach is not suitable for ALP because it solves a problem of limited capacity of connections between nodes with an unlimited capacity. On the
other hand, the ALP has unlimited connections. Moreover, in ALP-lp nodes have a limited capacity.

Still, the network flows can be used to model the ALP (but not the ALP-lp). We use a Ford-Fulkerson algorithm from \cite[Ford1956] as a basis for an algorithm described in section 
\ref[secc:analysis:ford-fulkerson]. The Ford-Fulkerson algorithm is shown as Algorithm \ref[alg:models:ford-fulkreson]

\bigskip

% \begfigure
\begalgo
\+{\bf function} \uppercase{ford--fulkerson}($G$) {\bf returns} the maximal flow\cr
\+\cr
\+\quad\cleartabs&{\bf variables:} \cleartabs&$G$\algfill&$G=(V,E)$ a network with flow capacity $c$,\cr 
\+               &                           &           &a source node $s$ and a sink node $t$\cr
\+               &                           &$f$\dotfill&a network flow\cr
\+               &                           &$c$\dotfill&a capacity of an edge or path\cr
\+               &                           &$p$\dotfill&a path in a graph\cr
\+               &                           &$(u,v)$\dotfill&an edge in $G$\cr
\+\cr
\+               &$f(u,v) \leftarrow 0$ for all edges $(u,v) \in G$\cr
\+               &{\bf while} $\exists p$ from $s$ to $t$ in $G$, such that $\forall (u,v) \in p\colon c(u,v) > 0$ {\bf do:}\cr
\+               &\quad\cleartabs&find $c(p) = \min\{c(u,v) : (u,v) \in p\}$\cr
\+               &               &{\bf for each} $(uv) \in p$ {\bf do:}\cr
\+               &               &\quad\cleartabs&$f(u,v) \leftarrow f(u,v) + c(p)$\cr
\+               &               &{\bf end for}\cr
\+               &{\bf end for}\cr
\+               &{\bf return} $f$\cr
\endalgo\nobreak\medskip
\label[alg:models:ford-fulkreson]\caption/a A pseudo-code of a Ford-Fulkerson algorithm.
% \endfigure

\bigskip

\label[sec:models:constraint-programming]
\sec Constraint programming

Constraint programming is a programming paradigm which uses constraints to describe a solution rather than to program a way of achieving such a solution. Out of many applications, the constraint 
programming can be used to model network problems. We discuss it in section \ref[secc:models:cp-networks]. A further description of constraint programming is contained in \cite[Dechter2003].

\secc Constraint satisfaction problem

The {\em Constraint satisfaction problem} (CSP\glos{CSP}{Constraint satisfaction problem}) consists of:

\begitems
* A set of variables ${\bf X} = \{x_1, \dots, x_n\}$
* For each variable $x_i$ a finite set $D_i$ of possible values (its {\em domain}),
* A set of {\em constraints} restricting the values that the variables can simultaneously take.
\enditems

A {\em solution} to a CSP is an assignment of value from its domain to every variable, in such a way that every constraint is satisfied. We may want to find:

\begitems
* just one solution, with no preference as to which one,
* all solutions,
* an optimal, or at least a good solution, given some objective function defined in terms of some or all of the variables.
\enditems

We can model all of the constraint problems using only the binary constraints (the constraints with two variables). The CSP can be represented as a constraint multigraph where the variables in the 
model are the nodes of the graph and the constraints over the variables in the model are the edges connecting the appropriate nodes. The edge $e(x,y)$ is {\em consistent} if for each value of $x$
there exists a value $y$ such that the constraint is satisfied.

The CSP is {\em arc consistent} if all of the edges in the constraint graph are consistent in both directions. The problem which cannot be transformed to arc consistent state does not have a solution.
However, the arc consistency does not ensure that the problem has a solution. For example let us have variables $X$, $Y$ and $Z$, all with a domain $\{0,1\}$ with constraints $X \neq Y$, $Y \neq Z$, 
$Z\neq X$. The problem is arc consistent, but is not feasible. However, the arc consistency is an important feature of a problem, since it helps to reduce the search space.

There are lots of algorithms to solve CSP. The most common of them is a {\em maintained arc consistency} (MAC\glos{MAC}{Maintained arc consistency algorithm}) presented in Algorithm \ref[alg:models:csp-mac].
This algorithm is currently the most used technique \cite[Bartak2007], since it combines search and maintaining of the solution consistency solution.

\begfigure
\begalgo
\+{\bf function} \uppercase{mac--labelling}($V$, $D$, $C$) {\bf returns} labelling or false \cr
\+\cr
\+\quad\cleartabs&{\bf variables:} \cleartabs&$V$\algfill&a set of variables,\cr 
\+               &                           &$D$\dotfill&a set of domains for variables from $V$\cr
\+               &                           &$C$\dotfill&a set of constraints\cr
\+               &                           &$x$\dotfill&a constrained variable\cr
\+               &                           &$v$\dotfill&a possible value of a constrained variable\cr
\+               &                           &$R$\dotfill&a return value, either a set of assigned values or false\cr
\+\cr
\+&{\bf if} all variables from $V$ are assigned {\bf then} return $V$ {\bf end if}\cr
\+&select not-yet assigned variable $x$ from $V$\cr
\+&{\bf for each} value $v$ from $D_x$ {\bf do:}\cr
\+&\quad\cleartabs&$(TestOK,D')\leftarrow consistent(V, D, C \cup \{x=v\})$\cr
\+&&{\bf if} $TestOK=true$ {\bf then}\cr
\+&&\quad\cleartabs&$R\leftarrow \mathbox{\uppercase{mac--labelling}}(V, D', C)$\cr
\+&&&{\bf if} $R\neq fail$ {\bf then} return $R$ {\bf end if}\cr
\+&&{\bf end if}\cr
\+&{\bf end for}\cr
\+&{\bf return} fail\cr
\endalgo\nobreak\medskip
\label[alg:models:csp-mac]\caption/a MAC algorithm from \cite[Bartak2007].
\endfigure

The algorithm consists of two phases repeated until the solution is found or until it is proved to not exist. The first phase is filtering of the variable domain by eliminating as many as possible 
values of the domain. The filtering can be achieved by transforming the problem into arc consistent problem. The filtration phase can end in three ways:

\begitems \style N
* The domain of some variable is empty. Therefore, the problem has no solution.
* The domains of all variables have just one element. The algorithm found the solution.
* The domains of some variables have more than one element while the problem is arc consistent.
\enditems

For the problem $P$, which is arc consistent but does not have a solution, we perform the distribution phase. In this phase we introduce a new constraint $c$ and create two new problems, $P \cup \{c\}$ and 
$P \cup \{\neg c\}$. If the problem $P$ has a solution, then at least one of the new problems has a solution. Afterwards, the filtering phase is run again. The typically used constraint $c$ is of
a form $x = v$ or $x < v$. However, any constraint can be used. The  {\em fist-fail} strategy is used to select a proper variable for the new constraint $c$. It picks a variable with the smallest domain.
Thus, it will be faster to discover, whether the problem is feasible or not.

The ALP is an optimization problem. We now discuss techniques used to find an optimal solution according to a given objective function. For only a few problems, we can search through the whole search
space and return a solution, which has the highest value of an objective function. For most of the problems, the time needed to find the best solution would be inadequately long. We can expect this
behavior, since the CSP is a NP-complete technique \cite[Garey1979]. However, there are many techniques to search the search space 
effectively to mostly find the best, or at least a good, solution. Commonly used technique is a method called {\em branch and bounds} presented in Algorithm \ref[alg:models:csp-bb]. The key idea of 
a branch and bound method is restricting the upper bound of a domain of the variable representing the value of an objective function. The branch and bound method can be sped up by using both
upper and lower bounds.

\begfigure
\begalgo
\+{\bf function} \uppercase{bb-min}($Variables$, $V$, $Constraints$) {\bf returns} optimal solution \cr
\+\cr
\+\quad\cleartabs&{\bf variables:} \cleartabs&$Variables$\algfill&a set of variables,\cr 
\+               &                           &$Constraints$\dotfill&a set of constraints\cr
\+               &                           &$Solution$\dotfill&a candidate optimal solution\cr
\+               &                           &$NewSolution$\dotfill&a temporary variable for a current solution\cr
\+               &                           &$Bound$\dotfill&a current bound\cr
\+               &                           &$V$\dotfill&a variable with a value of an objective function\cr
\+\cr
\+&$Bound \leftarrow sup$\cr
\+&$NewSolution \leftarrow fail$\cr
\+&{\bf repeat:}\cr
\+&\qc&$Solution \leftarrow NewSolution$\cr
\+&   &$NewSolution \leftarrow Solve(Variables, Constraints \cup \{V < Bound\})$\cr
\+&   &$Bound \leftarrow$ value of $V$ in $NewSolution$ (if any)\cr
\+&{\bf until} $NewSolution = fail$\cr
\+&{\bf return} Solution\cr
\endalgo\nobreak\medskip
\label[alg:models:csp-bb]\caption/a Branch and bounds method from \cite[Bartak2007].
\endfigure



\label[secc:models:cp-networks]
\secc Constraint programming problems in networks

As described in \cite[Simonis2006], the problems in networks can be easily modelled using a constraint programming. There are three usual types of the model -- a link-based model, a path-based model
and a node-based model. The models were originally formulated for placing demands over the computer networks. Therefore, a bandwidth constraints which use a bandwidth value ${\rm bw}(d)$ are added.
As we discussed earlier, these constraints are not suitable for ALP and we will not add them into the ALP model.

In the {\em link-based model}, for each demand we have one decision variable per link, which states if the link is used for this demand or not.

\begitems \style N
* For each demand $d$ and edge $e$, a variable $X_{de}$ with domain $\{0,1\}$ denotes whether the demand is routed over the edge.
* For every demand $d$, we also have one $\{0,1\}$ decision variable $Z_d$ which indicates if the demand is accepted or not.
\enditems

With the objective function 

$$\max\limits_{\{Z_d,X_{de}\}} \sum_{d\in D}{\rm val}(d)Z_d \eqmark$$

and constraints:

\label[models:eq:link]
$$ \forall d \in {\bf D}, \forall n \in {\bf N}: \sum_{e \in {\bf OUT}(n)}{X_{de}} - \sum_{e \in {\bf IN}(n)}{X_{de}} = \cases{\hfill -Z_d & $n = dest(d)$\cr\hfill Z_d & $n=orig(d)$ \cr\hfill 0 & otherwise} \eqmark$$

$$\forall e \in {\bf E}: \sum_{d \in {\bf D}}{{\rm bw}(d)X_{de} \leq {\rm cap}(e)} \eqmark $$

$$Z_d \in \{0,1\}\quad X_{de} \in \{0,1\}$$

\begfigure
\centerline{\inspic figs/model-constraint-link-1.pdf \kern2cm \inspic figs/model-constraint-link-2.pdf \kern2cm \inspic figs/model-constraint-link-3.pdf }\nobreak\medskip
\label[fig:models:constraint-link]\caption/f Effects enforced by the constraint imposed by the equation~\ref[models:eq:link].
\endfigure

As we can see on figure \ref[fig:models:constraint-link], the constraint imposed by the equation \ref[models:eq:link] is equivalent to the first Kirchhoff`s law known from electrical engineering.
There must be either no links from and to the node or there must be just one link ending in the node and just one link beginning in the node. There are two exceptions -- the origin node which is a
beginning of exactly one link and the destination node which is an end of exactly one node.

In the {\em path-based model}, the decision variables represent paths used to route demands. 

\begitems \style N
* For each demand $d$ we assume there are $path(d)$ possible paths for the demand.
* For each demand $d$ and possible path $i$, we introduce a $\{0,1\}$ variable $Y_{id}$ which denotes whether the demand is routed over the path.
* For each edge $e$ and path $i$ for demand $d$, a constant $h_{id}^{e}$ indicates whether the path is routed over the edge.
* For every demand $d$, we also have one $\{0,1\}$ decision variable $Z_d$ which indicates if the demand is accepted or not.
\enditems

\noindent With the objective function

$$\max\limits_{\{Z_d,T_{id}\}} \sum_{d\in {\bf D}}{\rm val}(d)Z_d \eqmark$$

\noindent and constraints:

$$\forall d \in {\bf D}: \sum_{1 \leq i \leq path(d)}{Y_{id} = Z_d} \eqmark$$

$$\forall e \in {\bf E}: \sum_{d \in {\bf D}}{{\rm bw}(d) \sum_{1 \leq i \leq path(d)}{h_{id}^e Y_{id} \leq {\rm cap}(e)}} \eqmark$$

$$Z_d \in \{0,1\}\quad Y_{id} \in \{0,1\}$$

In the {\em node-based model}, the decision variables represent successor relations between network nodes.

For each demand $d$ and each node $k$ in the network, we introduce an integer decision variable $S_{kd}$ with the following domain:

\label[models:eq:node]
$$S_{kd} :: \cases{\bigl\{sink(e) | e \in {\bf OUT}(k)\bigr\} & $k=orig(d)$ \cr orig(d) & $k=dest(d)$ \cr \{0\} \cup \bigl\{sink(e) | e \in {\bf OUT}(k)\bigr\} & otherwise} \eqmark$$

For each demand, the domain for a node contains all possible successors and the value 0, which indicates that the node is not used to route the demand. The destination node contains a back-link to
the source. The constraint is set so that for every demand $d$ the set 

$$\bigl\{\langle k, S_{dk} \rangle | S_{kd} \neq 0\bigr\} \eqmark$$

\noindent forms a cycle in the graph. The capacity constraint for each node can be expressed with a cumulative constraint which uses two arguments, a set of task given by {\em start}, {\em duration}
and {\em resource use} and a resource profile, given as a set of tuples {\em time point} and {\em resource limit}.

$${\rm cumulative}\Bigl(\bigl\{\langle S_{id},1,bw(d)\rangle |d\in {\bf D}\bigr\},
\bigl\{\langle l,m \rangle | 0 \leq l \leq n,m \bigr\}\Bigr) \eqmark$$

\noindent

$$\hbox{where }m = \cases{	\hfil\infty & $l=0$ \cr 
				\hfil cap(e) & $\exists e\in {\bf E}, \hbox{ st. } source(i)=e, sink(e) = j$ \cr 
				\hfil 0 & otherwise }$$

This model needs $|{\bf D}|$ cycle constraints and $|{\bf N}|$ cumulative constraints to express the conditions of the routing problem.

\begfigure
\centerline{\inspic figs/model-constraint-node-1.pdf }\nobreak\medskip
\label[fig:models:constraint-node]\caption/f Node-based constraint model. The constraint imposed in the equation \ref[models:eq:node] enforces that the nodes on the path form a cycle -- each node is
pointing to another node on the path and the destination node points to the original point.
\endfigure

\secc Constraint programming and ALP

ALP can be easily modelled as a constraint programming problem. The path-based model, as described in section \ref[secc:models:cp-networks], is suitable for ALP, since the expected number of paths 
is relatively low. Both link-based and node-based models solve not only the problem of optimal transfers, but they must deal with path-finding, as well. The duration of a path depends on a shipment
time. Therefore, the constrained model would need to compute it. This capability would make the model unnecessarily complex. Therefore, we use a path-based model as a basis for model solving ALP. 

\sec Mixed integer programming

The CSP based model for ALP consists mostly of sum constraints. Constraint programming can handle such models. Though, there is a better technique for such a model. We will now present {\em Mixed integer
programming} (MIP\glos{MIP}{Mixed integer programming}), which effectively deals with models based on sums and inequalities similar to the above mentioned model for planning of transfers in networks \cite[Holub2010].

\secc Linear and integer programming

Mixed integer programming is a method derived from a linear programming method. Linear programming problem is stated as follows \cite[Dantzig1951]:

Find the values of $\lambda_1, \lambda_2, \dots, \lambda_n$ which maximize the linear form

\label[eq:models:lp1]
$$\lambda_1c_1 + \lambda_2c_2 + \cdots + \lambda_n c_n \eqmark$$

\noindent subject to the conditions that

\label[eq:models:lp2]
$$\lambda_j\geq 0 \quad (j=1,2,\dots,n) \eqmark$$

\noindent and

\label[eq:models:lp3]
$$\matrix{
\lambda_1 a_{11} & + & \lambda_2 a_{12} & \cdots &+& \lambda_n a_{1n} &=& b_1\cr
\lambda_1 a_{21} & + & \lambda_2 a_{22} & \cdots &+& \lambda_n a_{2n} &=& b_2\cr
\vdots && \vdots &\ddots&  &&& \vdots\cr
\vdots && \vdots && \ddots &&& \vdots\cr
\vdots && \vdots &&& \ddots && \vdots\cr
\lambda_1 a_{m1} & + & \lambda_2 a_{m2} & \cdots &+& \lambda_n a_{mn} &=& b_m\cr
} \eqmark$$

There exists a straightforward process to convert any linear program into the form specified in the equations \ref[eq:models:lp1], \ref[eq:models:lp2] and \ref[eq:models:lp3]. The system of linear 
inequalities defines a polytope as a feasible region. The {\em simplex} algorithm, proposed in \cite[Dantzig1951], finds an optimum by traversing along the edges of polytope until it reaches the
vertex of the optimum solution. Worst-case time complexity of the simplex algorithm is exponential. However, in the average case the algorithm is polynomial.

\begfigure
\centerline{\picplaceholder{Simplex on a polytope}}\nobreak\medskip
\label[fig:models:polytope]\caption/f A twodimensional projection of a polytope defined by feasible region. Steps of the simplex algorithm and an objective function are demonstrated.
\endfigure

When we restrict the variables to contain only the integer values, we get the {\em Integer programming} problem (IP\glos{IP}{Integer programming}). Unfortunately, contrary to LP, the IP is an NP-complete 
problem \cite[Papadimitriou1981]. The binary variant of logical programming, i.e. the logical programming where variables have a $\{0,1\}$ domain is NP-complete and is a part of the Karp's 12 
NP-complete problems \cite[Karp1972]. Finally, when we combine linear and integer programming, we get the Mixed integer programming problem. This problem is NP-hard, as well. However, there exists several
efficient solvers to this problem such as the SCIP system \cite[Achterberg2008].

\secc Mixed integer program

The {\em mixed integer program} is defined as follows \cite[Achterberg2007]:

Given a matrix $A \in {\bbchar R}^{m \times n}$, vectors $b \in {\bbchar R}^m$, and $c \in {\bbchar R}^n$, and a subset $I \subseteq N = \{1,\dots,m\}$, the mixed integer program $MIP=(A,b,c,I)$ is to
solve

$$c^* = \min\left\{c^T x | Ax \leq b, x\in {\bbchar R}^n, x_j \in {\bbchar Z} \mathbox{ for all } j \in I \right\}$$

The vectors in the set $X_{MIP} = \left\{x \in {\bbchar R}^n | Ax \leq b, x_j \in {\bbchar Z} \mathbox{ for all } j \in I\right\}$ are called {\em feasible solutions} of MIP. A feasible solution
$x^* \in X_{MIP}$ is called {\em optimal} if its objective value satisfies $c^T x^* = c^*$.

In contrast to constraint programming, in mixed integer programming, we are restricted to linear constraints, a linear objective function and integer or real-valued domains. 
We define $l_j$ and $u_j$ as lower and upper bounds of a variable $x_j$. It holds that $l_j \leq x_j \leq u_j$. Next, we define a set of binary variables as $B = \{j\in I | l_j = 0 \mathbox{ and }
u_j = 1\}$. There exist the following specializations of MIP:

\begitems
* $I = \emptyset$: linear programs,
* $I = N$: integer programs,
* $B = I$: mixed binary programs, and
* $B = I = N$: Binary programs,
\enditems

\secc Solution strategies

As discussed in \cite[Achterberg2007], the MIP solvers use previously discussed branch and bounds method to find an optimal solution. First a solver uses a branching rule to branch a search tree. 
Then, it selects the next subproblem from the search tree to be processed. Afterwards, the selected node is a subject to a domain propagation. Finally, the LP relaxation of a node 
is strenghtened by the use of a cutting plane separation algorithm.

Commonly used branching technique is {\em branching on variables}. For a problem $Q$, if $x_j, j \in I$, is some integer variable with a fractional value $x_j^\prime$, we obtain two subproblems: 
one by adding the inequality $x_j \leq \lfloor x_j^\prime \rfloor$ (the {\em left subproblem} denoted as $Q_j^-$) and one by adding the inequality $x_j \geq \lceil x_j^\prime \rceil$ (the {\em right
subproblem} or $Q_j^+$). More complex branching is rarely incorporated into general MIP solvers.

Once the problem is divided into two subproblems, the solving process can continue with any subproblem that is a leaf of the current search tree. However, the search must handle with two, usually 
opposing, goals:

\begitems
* It must find good feasible MIP solutions to improve primal (upper) bound
* It must improve the global dual (lower) bound.
\enditems

The integral LP solutions tend to be deep in the search tree \cite[Linderoth1999]. Therefore, the {\em depth first search} seems to be the most natural choice. However, it does not fit well with the second
goal. This goal can be achieved with {\em best first search} method, which always selects a subproblem with the smallest dual bound of all remaining leaves in the tree. As a combination of both methods
we can use {\em best first search with plunging}. The method at first, as long as the current node has unprocessed children, selects one of the children as the next node. Otherwise, the plunging continues with one
of the current node's siblings. If no more unprocessed children or siblings are available, the current plunge is completed and a leaf from the tree with best dual bound is selected.

Afterwards, the solver tightens domains of variables by inspecting the constraints and the current domains of other variables at a local subproblem in the search tree. This process is called a {\em domain
propagation} or a {\em node processing}. LP relaxation cannot handle holes inside a domain. Therefore MIP solvers only alter bounds of a domain.

Finally, a cut separation phase occurs. The method iteratively refines a feasible set or objective function by adding new linear inequalities called {\em cuts}. There are two basic variants a 
{\em cut and branch} and {\em branch and cut} depending on whether the cutting planes are only generated at the root node or at local subproblems in the search tree, as well. Despite not being initially 
accepted, nowadays, the most common cut separation technique is {\em Gomory mixed integer cuts} described in \cite[Gomory1960]. The method first solves the problem while ignoring the integer requirement.
If the found solution is not an integer, then the method finds a hyperplane with a solution on one side and all feasible integer points on the other. Afterwards, it transforms the hyperplane to a new 
inequality and adds it to the problem.

\secc Mixed integer programming and ALP

Both the ALP and ALP-lp can be easily reformulated as a mixed integer programming problem. We can expect, that this model would have a better performance than CSP based model, since the path-based
model as described in section \ref[secc:models:cp-networks] uses constraints which are not easily evaluated. On the other hand, the MIP solvers are specialized and tuned up for such a type of constraints.

